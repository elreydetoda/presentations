# docker run --restart unless-stopped -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama docker.io/ollama/ollama:0.5.11

# docker container run -it -p 10300:10300 -v ~/whisperdata:/data --restart unless-stopped --name ha-stt-whisper-cpp -d docker.io/rhasspy/wyoming-whisper-cpp:1.1.0 --model medium.en --language en --download-dir /data --data-dir /data



services:
  homeassistant:
    container_name: homeassistant
    # image: "ghcr.io/home-assistant/home-assistant:2024.6.4"
    image: "ghcr.io/home-assistant/home-assistant:2025.4.4"
    volumes:
      - ./config:/config
      - ./local_media:/media/local
      - /etc/localtime:/etc/localtime:ro
      - /run/dbus:/run/dbus:ro
      # Intel QuickSync for camera decoding
      # - /dev/dri/renderD128:/dev/dri/renderD128
    restart: unless-stopped
    privileged: true
    network_mode: host
    depends_on:
      #- ha-stt-whisper
      - ollama
      - tts-piper
      - stt-whisper-cpp
      - tts-openWakeWord

        #ha-stt-whisper:
        #  container_name: ha-stt-whisper
        #  build:
        #    context: ./faster-whisper-cuda-docker/docker/cuda
        #    dockerfile: Dockerfile
        #    args:
        #      WYOMING_WHISPER_VERSION: "2.4.0"
        #  #command: ["--model", "small.en", "--language", "en", "--debug"]
        #  command: [ "--language", "en", "--debug"]
        #  volumes:
        #    - ~/whisperdata:/data
        #  ports:
        #    - "127.0.0.1:10300:10300"
        #  restart: unless-stopped
        #  runtime: nvidia
        #  deploy:
        #    resources:
        #      reservations:
        #        devices:
        #          - driver: nvidia
        #            count: 1
        #            capabilities: [gpu]

  tts-piper:
    container_name: ha-tts-piper
    image: docker.io/rhasspy/wyoming-piper:1.5.0
    volumes:
      - ./piper:/data
    ports:
      - "127.0.0.1:10200:10200"
    restart: unless-stopped
    command: ["--voice", "en_GB-alan-medium"]

  tts-openWakeWord:
    container_name: ha-tts-openWakeWord
    image: docker.io/rhasspy/wyoming-openwakeword:1.10.0
    volumes:
      - ./openWakeWord:/custom
    ports:
      - "127.0.0.1:10400:10400"
    restart: unless-stopped
    command: ["--preload-model", "ok_nabu", "--custom-model-dir", "/custom"]
  ollama:
    image: docker.io/ollama/ollama:0.5.11
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - ./ollama:/root/.ollama
    ports:
      - "127.0.0.1:11434:11434"
  stt-whisper-cpp:
    image: docker.io/rhasspy/wyoming-whisper-cpp:1.1.0
    restart: unless-stopped
    volumes:
      - ./whisperdata:/data
    ports:
      - "127.0.0.1:10300:10300"
    command: --model medium.en --language en --download-dir /data --data-dir /data
